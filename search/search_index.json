{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Yulai Xie (\u200b\u8c22\u200b \u200b\u96e8\u6765\u200b)","text":"<p>PhD, Chief Researcher @  Hitachi China Research Laboratory</p> <ul> <li> Last Update: 2025.03</li> <li> xie_yulai@outlook.com</li> <li> GitHub  ResearchGate  ORCID</li> <li>Reviewer for: Multimeida System, IEEE TMM, IJMLC, Cluster Computing, IET CV, ECCV etc.</li> </ul>"},{"location":"#news","title":"News","text":"<p>Latest Updates</p> 2025 <ul> <li>[Mar] Technical committee (ICCMS2025)</li> </ul> 2024 <ul> <li>[Dec] Invited talk (MCVR2024)</li> <li>[Jnl] Top Downloaded Article in IET Computer Vision</li> <li>[Jun] Digital simulation empowers industrial AI solutions</li> <li>[Mar] Hitachi Review </li> <li>[Mar] Hitachi Review(\u200b\u65e5\u672c\u200b\u8a9e\u200b)</li> <li>[Jan] Technical committee (ICCMS2024)</li> </ul> 2023 <ul> <li>[Nov] Medical Exhibition</li> <li>[Jul] AI Industrial Application</li> <li>[Jan] Chairman (ICCSM2023)</li> </ul> 2022 <ul> <li>[Aug] Invited talk report</li> <li>[Jul] Invited talk (ICCV2022)</li> </ul> 2020 <ul> <li>[Jun] Hitachi AI Blog</li> </ul>"},{"location":"#research-interests","title":"Research Interests","text":"<p>Core Research Areas</p>"},{"location":"#ai-fundamentals","title":"AI Fundamentals","text":"<ul> <li> Machine Learning</li> <li> Computer Vision</li> <li> Multi-Modal Analysis (Vision, Audio, Language, Sensor)</li> <li> AI-based Generative Content (Time-series, Image)</li> <li> 3D Reconstruction/3D Generation</li> <li> AI Methods for Domain Applications (Optics)</li> <li> Large Language Model/Multi-Modal Large Language Model </li> </ul>"},{"location":"#ai-applications","title":"AI Applications","text":"<ul> <li> Industrial &amp; Logistics</li> <li> Crowd Simulation</li> <li> Traffic Analysis</li> <li> Elder Care Solutions</li> <li> Industry Applications of Large Language Models (DeepSeek, qwen, etc.) </li> </ul>"},{"location":"#education-experience","title":"Education &amp; Experience","text":"<p>Education &amp; Professional Journey</p> <p>"},{"location":"#education","title":"Education","text":"<ul> <li>2010-2014 Ph.D in Engineering<ul> <li>Hokkaido University, Japan</li> <li> CSC Scholarship</li> </ul> </li> <li>2004-2010 Bachelor &amp; Master in Engineering<ul> <li>Tianjin University, China</li> </ul> </li> <li>2013 Intern<ul> <li>Iowa University, USA"},{"location":"#professional-experience","title":"Professional Experience","text":"<ul> <li>2014-Present Chief Researcher<ul> <li>Hitachi China Research Laboratory, China</li> <li>Focus on CV, AI, AIGC Industry Applications</li> <li>Exploring Technical Innovations with GenAI, LLM, MLM</li> </ul> </li> <li>2014 Research Training<ul> <li>Hitachi Central Research Laboratory, Japan </li> </ul> </li> </ul>"},{"location":"#project-experience","title":"Project Experience","text":"<p>Project Portfolio</p> <p>"},{"location":"#industry-applications","title":"Industry Applications","text":"<ul> <li> Public Security Video Surveillance (2014)</li> <li> Airport Ground Operation Analysis (2017)</li> <li> Multinational Fast Food Visual Ordering (2019)</li> <li> Leading Pharmaceutical Company Behavior Monitoring (2020)</li> <li> Major Beverage Company Safety Management (2021)</li> <li> Leading Auto Parts Quality Inspection (2022)</li> <li> Multinational Logistics Warehouse Behavior Analysis (2023)</li> <li> Power Company Safety Compliance (2024)"},{"location":"#research-exploration","title":"Research Exploration","text":"<ul> <li> Vision-based Public Transportation Management (Chongqing University)</li> <li> Sensor-based Public Area Crowd Analysis (Tsinghua University)</li> <li> Multi-modal Video Understanding (BUCT)</li> <li> Image-based 3D Reconstruction (BUCT)</li> <li> AI-based Optical Systems (BUCT)</li> <li> Industry Applications of Large Language Models (DeepSeek)  </li> </ul>"},{"location":"#publications","title":"Publications","text":"<p>Selected Recent Publications</p> <p> View Full Publication List </p>"},{"location":"#journal-papers","title":"Journal Papers","text":"<ol> <li> <p>Ren, Fang, Yulai Xie (co-first author), Xiaoning Pi and Xiaohui Wang. \"Bridge the gap between simulated and real-world data in optical fiber mode decomposition for accuracy improvement: A deep learning-based co-learning framework with visual similarity-based matching\". Expert Systems with Applications 256 (2024): 124937.  DOI  (JCR Q1)</p> </li> <li> <p>Xie, Yulai, Jingjing Niu, Yang Zhang, and Fang Ren. \"Global-Shared Text Representation Based Multi-Stage Fusion Transformer Network for Multi-Modal Dense Video Captioning.\" IEEE Transactions on Multimedia, (2023).  DOI  (JCR Q1)</p> </li> <li> <p>Xie, Yulai, Jingjing Niu, Yang Zhang, and Fang Ren. \"Multisize Patched Spatial-Temporal Transformer Network for Short-and Long-Term Crowd Flow Prediction\". IEEE Transactions on Intelligent Transportation Systems, (2022).  DOI  (JCR Q1)</p> </li> <li> <p>Jingjing Niu, Yulai Xie (co-first author), Yang Zhang, and Fang Ren. \"Tri-Modal Dense Video Captioning Based on Fine-Grained Aligned Text and Anchor-Free Event Proposals Generator\". International Journal of Pattern Recognition and Artificial Intelligence, (2022).  DOI</p> </li> <li> <p>Xie, Yulai, Yang Zhang, and Fang Ren. \"Temporal-Enhanced Graph Convolution Network for Skeleton-Based Action Recognition.\" IET Computer Vision, (2022).  DOI  (2022 Top Downloaded Article)</p> </li> </ol>"},{"location":"#papers-under-review","title":"Papers Under Review","text":"<ol> <li> <p>Ren, Fang, Xie, Yulai (co-first author), Pi,Xiaoning. \"Query-Based Neural Network for Long-Range Prediction of Optical Spatio-temporal Dynamics in Multimode Fibers.\", Expert Systems with Applications, (2025). (in Revision)  (JCR Q1)</p> </li> <li> <p>Xie, Yulai, Pi, Xiaoning, Zhang,Yang, and Ren,Fang. \"Structured Guided Diffusion Models for Industrial Defect Image Generation.\" Knowledge-based System, (2025). (in Revision)  (JCR Q1)</p> </li> </ol>"},{"location":"#conference-papers","title":"Conference Papers","text":"<ol> <li> <p>Pi, XiaoNing, YuLai Xie (co-first author), Yang Zhang, XiaoHui Wang, and Fang Ren. \"Automatic Iterative Diversity Improvement for Defect Data Generation.\" In Proceedings of the 2024 16th International Conference on Computer Modeling and Simulation, 41-47. ICCMS '24. ACM, 2024.  DOI</p> </li> <li> <p>Wang, Xiaohui, Yulai Xie (co-first author), Yang Zhang, Xiaoning Pi, and Fang Ren. \"Digital Simulation-Based Data Generation for Quality Inspection.\" In ICCMS 2023, 6. 2023.  DOI</p> </li> <li> <p>Zhang, Yanfei, Yulai Xie (co-first author), Yang Zhang, Yiruo Dai, and Fang Ren. \"VSSum: A Virtual Surveillance Dataset for Video Summary.\" In ICCCV 2022, 7, 2022.  DOI</p> </li> </ol>"},{"location":"#patents","title":"Patents","text":"<p>Patent Portfolio</p> Page Views:  Unique Visitors:"},{"location":"#patent-list","title":"Patent List","text":"<p> View Full List (20+) </p> <ul> <li>Focus areas: CV Applications, AI Applications, GenAI Applications, Industrial Solutions, Crowd Analysis, etc.</li> </ul>"},{"location":"chinese/","title":"\u8c22\u200b\u96e8\u6765","text":"<p>\u200b\u535a\u58eb\u200b\uff0c\u200b\u9ad8\u7ea7\u200b\u7814\u7a76\u5458\u200b, \u200b\u4f01\u4e1a\u200b\u5bfc\u5e08\u200b@ \u200b\u65e5\u7acb\u200b\u4e2d\u56fd\u200b\u7814\u7a76\u9662\u200b</p> <ul> <li> \u200b\u66f4\u65b0\u200b: 2025.03</li> <li> xie_yulai@outlook.com  GitHub  ResearchGate  ORCID</li> <li>\u200b\u671f\u520a\u200b/\u200b\u4f1a\u8bae\u200b\u5ba1\u7a3f\u4eba\u200b: \u200b\u67e5\u770b\u200b\u5217\u8868\u200b </li> </ul> <p>\u200b\u6700\u65b0\u200b\u52a8\u6001\u200b</p> 2025 <ul> <li>[3\u200b\u6708\u200b] \u200b\u6280\u672f\u200b\u59d4\u5458\u4f1a\u200b (ICCMS2025)</li> </ul> 2024 <ul> <li>[12\u200b\u6708\u200b] \u200b\u7279\u9080\u200b\u62a5\u544a\u200b (MCVR2024)</li> <li>[7\u200b\u6708\u200b] Top Downloaded Article in IET Computer Vision</li> <li>[6\u200b\u6708\u200b] \u200b\u57fa\u4e8e\u200b\u6570\u5b57\u6a21\u62df\u200b\u7684\u200b\u73b0\u573a\u200b\u573a\u666f\u200b\u521b\u5efa\u200b\u6280\u672f\u200b|\u200b\u5168\u7a0b\u200b\u8d4b\u80fd\u200b\u5de5\u4e1a\u200bAI\u200b\u89e3\u51b3\u65b9\u6848\u200b</li> <li>[3\u200b\u6708\u200b] Hitachi Review</li> <li>[3\u200b\u6708\u200b] \u200b\u65e5\u7acb\u200b\u8a55\u8ad6\u200b(\u200b\u65e5\u672c\u200b\u8a9e\u200b)</li> <li>[1\u200b\u6708\u200b] \u200b\u6280\u672f\u200b\u59d4\u5458\u4f1a\u200b (ICCMS2024)</li> </ul> 2023 <ul> <li>[11\u200b\u6708\u200b] \u200b\u79d1\u6280\u200b\u8d4b\u80fd\u200b\u4ea7\u4e1a\u200b\u521b\u65b0\u200b\u3001\u200b\u5171\u7b51\u200b\u5065\u5eb7\u200b\u7f8e\u597d\u672a\u6765\u200b</li> <li>[7\u200b\u6708\u200b] AI\u200b\u5b88\u62a4\u200b\u751f\u547d\u200b \u200b\u667a\u6167\u200b\u4e0e\u200b\u5b89\u5168\u200b\u540c\u884c\u200b</li> <li>[1\u200b\u6708\u200b] \u200b\u4f1a\u8bae\u200b\u4e3b\u5e2d\u200b (ICCSM2023)</li> </ul> 2022 <ul> <li>[8\u200b\u6708\u200b] \u200b\u65e5\u7acb\u200b\u4e2d\u56fd\u200b\u7814\u7a76\u9662\u200b\u53d7\u9080\u200b\u6f14\u8bb2\u200b</li> <li>[7\u200b\u6708\u200b] \u200b\u7279\u9080\u200b\u62a5\u544a\u200b (ICCCV2022)</li> </ul> 2020 <ul> <li>[6\u200b\u6708\u200b] \u200b\u65e5\u7acb\u200bAI\u200b\u535a\u5ba2\u200b\uff1a\u200b\u81ea\u52a8\u200b\u5ba2\u6d41\u200b\u4f30\u8ba1\u200b</li> </ul> <p>\u200b\u7814\u7a76\u200b\u9886\u57df\u200b</p> <p>"},{"location":"chinese/#ai","title":"AI\u200b\u57fa\u7840\u200b\u7814\u7a76","text":"<ul> <li> \u200b\u673a\u5668\u200b\u5b66\u4e60\u200b   \u200b\u8ba1\u7b97\u673a\u200b\u89c6\u89c9\u200b</li> <li> \u200b\u591a\u200b\u6a21\u6001\u200b\u5206\u6790\u200b(\u200b\u89c6\u89c9\u200b,\u200b\u542c\u89c9\u200b,\u200b\u8bed\u8a00\u200b,\u200b\u4f20\u611f\u5668\u200b)</li> <li> AIGC (\u200b\u65f6\u5e8f\u200b\u6570\u636e\u200b,\u200b\u56fe\u50cf\u200b\u6570\u636e\u200b\u751f\u6210\u200b)</li> <li> \u200b\u6570\u503c\u200b\u6a21\u62df\u200b/\u200b\u6570\u5b57\u200b\u5b6a\u751f\u200b </li> <li> \u200b\u4e09\u7ef4\u91cd\u5efa\u200b/\u200b\u4e09\u7ef4\u200b\u751f\u6210\u200b</li> <li> \u200b\u5927\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b/\u200b\u591a\u200b\u6a21\u6001\u200b\u5927\u200b\u6a21\u578b\u200b  <p>\u200b\u6559\u80b2\u200b\u4e0e\u200b\u804c\u4e1a\u200b\u53d1\u5c55\u200b</p> <p>"},{"location":"chinese/#ai_1","title":"AI\u200b\u5e94\u7528\u200b\u7814\u7a76","text":"<ul> <li> \u200b\u5de5\u4e1a\u200b\u5236\u9020\u200b\u4e0e\u200b\u7269\u6d41\u200b</li> <li> \u200b\u4eba\u7fa4\u200b\u6a21\u62df\u200b</li> <li> \u200b\u4ea4\u901a\u200b\u5206\u6790\u200b</li> <li> \u200b\u517b\u8001\u200b\u89e3\u51b3\u65b9\u6848\u200b</li> <li> AI\u200b\u65b9\u6cd5\u200b\u7684\u200b\u9886\u57df\u200b\u5e94\u7528\u200b(\u200b\u5149\u5b66\u200b)</li> <li> \u200b\u5927\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b(DeepSeek,qwen\u200b\u7b49\u200b)\u200b\u7684\u200b\u884c\u4e1a\u200b\u5e94\u7528\u200b  </li> </ul>"},{"location":"chinese/#_2","title":"\u6559\u80b2\u200b\u7ecf\u5386","text":"<ul> <li>2010-2014 \u200b\u5de5\u5b66\u200b\u535a\u58eb\u200b<ul> <li>\u200b\u5317\u6d77\u9053\u200b\u5927\u5b66\u200b\uff0c\u200b\u65e5\u672c\u200b</li> <li> \u200b\u56fd\u5bb6\u200b\u516c\u6d3e\u200b\u5956\u5b66\u91d1\u200b\u7559\u5b66\u200b</li> </ul> </li> <li>2008-2010 \u200b\u5de5\u5b66\u200b\u7855\u58eb\u200b<ul> <li>\u200b\u5929\u6d25\u5927\u5b66\u200b\uff0c\u200b\u4e2d\u56fd\u200b</li> </ul> </li> <li>2004-2008 \u200b\u5de5\u5b66\u200b,\u200b\u7ba1\u7406\u200b\u5b66\u58eb\u200b<ul> <li>\u200b\u5929\u6d25\u5927\u5b66\u200b\uff0c\u200b\u4e2d\u56fd\u200b</li> </ul> </li> <li>2013 \u200b\u5b9e\u4e60\u200b<ul> <li>\u200b\u7231\u8377\u534e\u200b\u5927\u5b66\u200b\uff0c\u200b\u7f8e\u56fd\u200b</li> </ul> </li> <li>2013 \u200b\u5b9e\u4e60\u200b<ul> <li>\u200b\u9996\u5c14\u200b\u5927\u5b66\u200b\uff0c\u200b\u97e9\u56fd\u200b <p>\u200b\u9879\u76ee\u200b\u7ecf\u5386\u200b</p> <p>"},{"location":"chinese/#_3","title":"\u5de5\u4f5c\u200b\u7ecf\u5386","text":"<ul> <li>2014-\u200b\u81f3\u4eca\u200b \u200b\u9ad8\u7ea7\u200b\u7814\u7a76\u5458\u200b<ul> <li>\u200b\u65e5\u7acb\u200b\u4e2d\u56fd\u200b\u7814\u7a76\u9662\u200b, \u200b\u4e2d\u56fd\u200b</li> <li>\u200b\u81f4\u529b\u4e8e\u200bCV,AI,AIGC\u200b\u7684\u200b\u6280\u672f\u200b\u843d\u5730\u200b</li> <li>\u200b\u63a2\u7d22\u200bGenAI,LLM,MLM\u200b\u5e26\u6765\u200b\u7684\u200b\u6280\u672f\u9769\u65b0\u200b</li> </ul> </li> <li>2014 \u200b\u7814\u4fee\u200b<ul> <li>\u200b\u65e5\u7acb\u200b\u4e2d\u592e\u200b\u7814\u7a76\u6240\u200b, \u200b\u65e5\u672c\u200b </li> </ul> </li> </ul>"},{"location":"chinese/#_4","title":"\u843d\u5730\u200b\u5bfc\u5411","text":"<ul> <li> \u200b\u516c\u5171\u5b89\u5168\u200b\u89c6\u9891\u200b\u76d1\u63a7\u200b (2014)</li> <li> \u200b\u673a\u573a\u200b\u5730\u52e4\u200b\u4f5c\u4e1a\u200b\u8f66\u7aef\u200b\u5206\u6790\u200b (2017)</li> <li> \u200b\u8de8\u56fd\u200b\u5feb\u9910\u5e97\u200b\u89c6\u89c9\u200b\u70b9\u9910\u200b (2019)</li> <li> \u200b\u5934\u90e8\u200b\u5236\u836f\u200b\u4f01\u4e1a\u200b\u5382\u533a\u200b\u884c\u4e3a\u89c4\u8303\u200b (2020)</li> <li> \u200b\u5927\u578b\u200b\u996e\u6599\u200b\u4f01\u4e1a\u200b\u5382\u533a\u200b\u5b89\u5168\u200b\u89c4\u8303\u200b (2021)</li> <li> \u200b\u5934\u90e8\u200b\u6c7d\u914d\u200b\u4f01\u4e1a\u200b\u4ea7\u200b\u7ebf\u8d28\u91cf\u200b\u68c0\u6d4b\u200b (2022)</li> <li> \u200b\u8de8\u56fd\u200b\u7269\u6d41\u200b\u4f01\u4e1a\u200b\u4ed3\u5e93\u200b\u884c\u4e3a\u200b\u4f20\u611f\u200b\u5206\u6790\u200b (2023)</li> <li> \u200b\u7535\u529b\u4f01\u4e1a\u200b\u5382\u533a\u200b\u5b89\u5168\u200b\u89c4\u8303\u200b (2024)  <p>\u200b\u8fd1\u671f\u200b\u8bba\u6587\u200b</p> <p>\u200b\u67e5\u770b\u200b\u5b8c\u6574\u200b\u8bba\u6587\u200b\u5217\u8868\u200b </p> <p>\u200b\u4e13\u5229\u200b</p> \u200b\u9875\u9762\u200b\u8bbf\u95ee\u91cf\u200b\uff1a \u200b\u72ec\u7acb\u200b\u8bbf\u5ba2\u200b\u6570\u200b\uff1a"},{"location":"chinese/#_5","title":"\u524d\u6cbf\u200b\u63a2\u7d22","text":"<ul> <li> \u200b\u57fa\u4e8e\u200b\u89c6\u89c9\u200b\u7684\u200b\u516c\u5171\u200b\u4ea4\u901a\u7ba1\u7406\u200b(\u200b\u91cd\u5927\u200b\u5408\u4f5c\u200b)</li> <li> \u200b\u57fa\u4e8e\u200b\u4f20\u611f\u200b\u7684\u200b\u516c\u5171\u200b\u533a\u57df\u200b\u4eba\u7fa4\u200b\u5206\u6790\u200b(\u200b\u6e05\u534e\u200b\u5408\u4f5c\u200b)</li> <li> \u200b\u591a\u200b\u6a21\u6001\u200b\u89c6\u9891\u200b\u7406\u89e3\u200b\u5206\u6790\u200b(\u200b\u5317\u79d1\u200b\u5408\u4f5c\u200b)</li> <li> \u200b\u57fa\u4e8e\u200b\u56fe\u50cf\u200b\u7684\u200b\u4e09\u7ef4\u91cd\u5efa\u200b(\u200b\u5317\u79d1\u200b\u5408\u4f5c\u200b)</li> <li> \u200b\u57fa\u4e8e\u200bAI\u200b\u7684\u200b\u5149\u5b66\u7cfb\u7edf\u200b(\u200b\u5317\u79d1\u200b\u5408\u4f5c\u200b)</li> <li> \u200b\u57fa\u4e8e\u200b\u5927\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b(DeepSeek)\u200b\u7684\u200b\u884c\u4e1a\u200b\u5e94\u7528\u200b\u9769\u65b0\u200b  </li> </ul>"},{"location":"chinese/#_6","title":"\u671f\u520a\u8bba\u6587","text":"<ol> <li> <p>Ren, Fang, Yulai Xie (\u200b\u5171\u540c\u200b\u4e00\u4f5c\u200b), Xiaoning Pi \u200b\u548c\u200b Xiaohui Wang. \"Bridge the gap between simulated and real-world data in optical fiber mode decomposition for accuracy improvement: A deep learning-based co-learning framework with visual similarity-based matching\". Expert Systems with Applications 256 (2024): 124937.  DOI  (JCR Q1|\u200b\u4e2d\u79d1\u9662\u200b\u4e00\u533a\u200b)</p> </li> <li> <p>Xie, Yulai, Jingjing Niu, Yang Zhang, \u200b\u548c\u200b Fang Ren. \"Global-Shared Text Representation Based Multi-Stage Fusion Transformer Network for Multi-Modal Dense Video Captioning.\" IEEE Transactions on Multimedia, (2023).  DOI (JCR Q1|\u200b\u4e2d\u79d1\u9662\u200b\u4e00\u533a\u200b)</p> </li> <li> <p>Xie, Yulai, Jingjing Niu, Yang Zhang, \u200b\u548c\u200b Fang Ren. \"Multisize Patched Spatial-Temporal Transformer Network for Short-and Long-Term Crowd Flow Prediction\". IEEE Transactions on Intelligent Transportation Systems, (2022).  DOI (JCR Q1|\u200b\u4e2d\u79d1\u9662\u200b\u4e00\u533a\u200b)</p> </li> <li> <p>Jingjing Niu, Yulai Xie (\u200b\u5171\u540c\u200b\u4e00\u4f5c\u200b), Yang Zhang, \u200b\u548c\u200b Fang Ren. \"Tri-Modal Dense Video Captioning Based on Fine-Grained Aligned Text and Anchor-Free Event Proposals Generator\". International Journal of Pattern Recognition and Artificial Intelligence, (2022).  DOI</p> </li> <li> <p>Xie, Yulai, Yang Zhang, \u200b\u548c\u200b Fang Ren. \"Temporal-Enhanced Graph Convolution Network for Skeleton-Based Action Recognition.\" IET Computer Vision, (2022).  DOI  (2022 Top Downloaded Article)</p> </li> </ol>"},{"location":"chinese/#_7","title":"\u5728\u200b\u6295\u200b\u8bba\u6587","text":"<ol> <li> <p>Ren, Fang, Xie, Yulai (\u200b\u5171\u540c\u200b\u4e00\u4f5c\u200b), Pi,Xiaoning. \"Query-Based Neural Network for Long-Range Prediction of Optical Spatio-temporal Dynamics in Multimode Fibers.\", Expert Systems with Applications, (2025). (in Revision) (JCR Q1|\u200b\u4e2d\u79d1\u9662\u200b\u4e00\u533a\u200b)</p> </li> <li> <p>Xie, Yulai, Pi, Xiaoning, Zhang,Yang, and Ren,Fang. \"Structured Guided Diffusion Models for Industrial Defect Image Generation.\" Knowledge-based System, (2025). (in Revision) (JCR Q1|\u200b\u4e2d\u79d1\u9662\u200b\u4e00\u533a\u200b)</p> </li> </ol>"},{"location":"chinese/#_8","title":"\u4f1a\u8bae\u200b\u8bba\u6587","text":"<ol> <li> <p>Pi, XiaoNing, YuLai Xie (\u200b\u5171\u540c\u200b\u4e00\u4f5c\u200b), Yang Zhang, XiaoHui Wang, \u200b\u548c\u200b Fang Ren. \"Automatic Iterative Diversity Improvement for Defect Data Generation.\" In Proceedings of the 2024 16th International Conference on Computer Modeling and Simulation, 41-47. ICCMS '24. ACM, 2024.  DOI</p> </li> <li> <p>Wang, Xiaohui, Yulai Xie (\u200b\u5171\u540c\u200b\u4e00\u4f5c\u200b), Yang Zhang, Xiaoning Pi, \u200b\u548c\u200b Fang Ren. \"Digital Simulation-Based Data Generation for Quality Inspection.\" In ICCMS 2023, 6. 2023.  DOI</p> </li> <li> <p>Zhang, Yanfei, Yulai Xie (\u200b\u5171\u540c\u200b\u4e00\u4f5c\u200b), Yang Zhang, Yiruo Dai, \u200b\u548c\u200b Fang Ren. \"VSSum: A Virtual Surveillance Dataset for Video Summary.\" In ICCCV 2022, 7, 2022.  DOI</p> </li> </ol>"},{"location":"chinese/#_9","title":"\u4e13\u5229\u200b\u5217\u8868","text":"<p> \u200b\u67e5\u770b\u200b\u5b8c\u6574\u200b\u5217\u8868\u200b(20+)</p> <ul> <li>\u200b\u4e3b\u8981\u200b\u9886\u57df\u200b\uff1a CV\u200b\u5e94\u7528\u200b, AI\u200b\u5e94\u7528\u200b, GenAI\u200b\u5e94\u7528\u200b, \u200b\u5de5\u4e1a\u200b\u89e3\u51b3\u65b9\u6848\u200b, \u200b\u4eba\u7fa4\u200b\u5206\u6790\u200b\u7b49\u200b</li> </ul>"},{"location":"publications/","title":"Publications","text":""},{"location":"publications/#journal-papers","title":"Journal Papers","text":"<p>2025</p> <ol> <li> <p>Ren, Fang, Xie, Yulai (co-first author), Pi,Xiaoning. \"Query-Based Neural Network for Long-Range Prediction of Optical Spatio-temporal Dynamics in Multimode Fibers.\", Expert Systems with Applications, 2025. (in Revision) (JCR Q1|\u200b\u4e2d\u79d1\u9662\u200b\u4e00\u533a\u200b)</p> </li> <li> <p>Xie, Yulai, Pi, Xiaoning, Zhang,Yang, and Ren,Fang. \"Structured Guided Diffusion Models for Industrial Defect Image Generation.\" Knowledge-based System, 2025. (in Revision) (JCR Q1|\u200b\u4e2d\u79d1\u9662\u200b\u4e00\u533a\u200b)</p> </li> </ol> <p>2024</p> <ol> <li>Ren, Fang, Xie, Yulai (co-first author), Pi,Xiaoning and Wang,Xiaohui . \"Bridge the gap between simulated and real-world data in optical fiber mode decomposition for accuracy improvement: A deep learning-based co-learning framework with visual similarity-based matching\". Expert Systems with Applications 256 (2024.12.5): 124937.  DOI  (JCR Q1|\u200b\u4e2d\u79d1\u9662\u200b\u4e00\u533a\u200b)</li> </ol> <p>2023</p> <ol> <li> <p>Xie, Yulai, Jingjing Niu, Yang Zhang, and Fang Ren. \"Global-Shared Text Representation Based Multi-Stage Fusion Transformer Network for Multi-Modal Dense Video Captioning.\" IEEE Transactions on Multimedia, August 23, 2023.  DOI  (JCR Q1|\u200b\u4e2d\u79d1\u9662\u200b\u4e00\u533a\u200b)</p> </li> <li> <p>Han, Zhenyu, Siran Ma, Changzheng Gao, Erzhuo Shao, Yulai Xie, Yang Zhang, Lu Geng, and Yong Li. \"Disease Simulation in Airport Scenario Based on Individual Mobility Model.\" ACM Transactions on Intelligent Systems and Technology, May 20, 2023.  DOI</p> </li> <li> <p>\u200b\u9648\u536b\u661f\u200b, \u200b\u8c22\u200b\u96e8\u6765\u200b. \"\u200b\u57fa\u4e8e\u200b\u65f6\u7a7a\u200b\u903b\u8f91\u200b\u7684\u200b\u9ad8\u7a7a\u4f5c\u4e1a\u200b\u8fdd\u89c4\u200b\u68c0\u6d4b\u200b\u65b9\u6cd5\u200b\u7814\u7a76\u200b\". \u200b\u673a\u7535\u200b\u5b89\u5168\u200b, 2023\u200b\u5e74\u200b6\u200b\u6708\u200b</p> </li> </ol> <p>2022</p> <ol> <li> <p>Xie, Yulai, Jingjing Niu, Yang Zhang, and Fang Ren. \"Multisize Patched Spatial-Temporal Transformer Network for Short-and Long-Term Crowd Flow Prediction\". IEEE Transactions on Intelligent Transportation Systems, 2022.  DOI  (JCR Q1|\u200b\u4e2d\u79d1\u9662\u200b\u4e00\u533a\u200b)</p> </li> <li> <p>Jingjing Niu, Yulai Xie (co-first author), Yang Zhang, and Fang Ren. \"Tri-Modal Dense Video Captioning Based on Fine-Grained Aligned Text and Anchor-Free Event Proposals Generator\". International Journal of Pattern Recognition and Artificial Intelligence, 2022.  DOI</p> </li> <li> <p>Shao, Erzhuo, Zhenyu Han, Yulai Xie, Yang Zhang, Lu Geng, and Yong Li. \"Interior Individual Trajectory Simulation with Population Distribution Constraint\". ACM Transactions on Intelligent Systems and Technology, 2022.  DOI</p> </li> <li> <p>Xie, Yulai, Yang Zhang, and Fang Ren. \"Temporal-Enhanced Graph Convolution Network for Skeleton-Based Action Recognition.\" IET Computer Vision, 2022, 266\u201379.  DOI  (2022 Top Downloaded Article)</p> </li> </ol>"},{"location":"publications/#conference-papers","title":"Conference Papers","text":"<p>2024</p> <ol> <li>Pi, XiaoNing, YuLai Xie (co-first author), Yang Zhang, XiaoHui Wang, and Fang Ren. \"Automatic Iterative Diversity Improvement for Defect Data Generation.\" In Proceedings of the 2024 16th International Conference on Computer Modeling and Simulation, 41-47. ICCMS '24. ACM, 2024.  DOI</li> </ol> <p>2023</p> <ol> <li>Wang, Xiaohui, Yulai Xie (co-first author), Yang Zhang, Xiaoning Pi, and Fang Ren. \"Digital Simulation-Based Data Generation for Quality Inspection.\" In ICCMS 2023, 6. 2023.  DOI</li> </ol> <p>2022</p> <ol> <li>Zhang, Yanfei, Yulai Xie (co-first author), Yang Zhang, Yiruo Dai, and Fang Ren. \"VSSum: A Virtual Surveillance Dataset for Video Summary.\" In ICCCV 2022, 7, 2022.  DOI</li> </ol>"},{"location":"publications/#earlier-publications","title":"Earlier Publications","text":"2021-2017 <ol> <li> <p>Xie, Yulai, Yang Zhang, and Fang Ren. \"Temporal-Aware Graph Convolution Network for Skeleton-Based Action Recognition.\" ACM International Conference Proceeding Series, 2021, 83\u201390.  DOI</p> </li> <li> <p>Fan, Xiaojie, Fang Ren, Yulai Xie, Yiying Zhang, Jingjing Niu, Jingyu Zhang, and Jianping Wang. \"Mitigating Ambiguity by Deep-Learning-Based Modal Decomposition Method.\" Optics Communications, September 2020.  DOI</p> </li> <li> <p>Fan, Xiaojie, Lina Wang, Fang Ren, Yulai Xie, Xiang Lu, Yiying Zhang, Tianwen Zhangsun, Wei Chen, and Jianping Wang. \"Feature Fusion-Based Multi-Task ConvNet for Simultaneous Optical Performance Monitoring and Bit-Rate/Modulation Format Identification.\" IEEE Access PP (September 2, 2019).  DOI</p> </li> <li> <p>Fan, Xiaojie, Yulai Xie, Fang Ren, Yiying Zhang, Xiaoshan Huang, Wei Chen, Tianwen Zhangsun, and Jianping Wang. \"Joint Optical Performance Monitoring and Modulation Format/Bit-Rate Identification by CNN-Based Multi-Task Learning.\" IEEE Photonics Journal 10 (September 11, 2018).  DOI</p> </li> <li> <p>Liu, Guojin, Zhenzhi Yin, Yunjian Jia, and Yulai Xie. \"Passenger Flow Estimation Based on Convolutional Neural Network in Public Transportation System.\" Knowledge-Based Systems 123 (February 1, 2017).  DOI (JCR Q1|\u200b\u4e2d\u79d1\u9662\u200b\u4e00\u533a\u200b)</p> </li> </ol> 2013-2010 <ol> <li> <p>Xie, Yulai, Satoshi Kanai, and Hiroaki Date. \"An Efficient Simulation of Skin Contact Deformation for Virtual Ergonomic Assessments of Handheld Products.\" International Journal of CAD/CAM 13 (January 1, 2013): 81-95.   (Gaheon Sindoh Foundation, Society of CAD/CAM Engineers, The Gaheon Award 2013)</p> </li> <li> <p>Xie, Yulai, Satoshi Kanai, and Hiroaki Date. \"Anatomy-Based Variational Modeling of Digital Hand and Its Verification.\" In DHM/HCII 2013, 8026:384-92, 2013.  DOI</p> </li> <li> <p>Xie, Yulai, Li Xingfei, Lu Jingwei, and Gao Yabiao. \"Underwater Image Real-Time Registration Method based on SURF.\" Journal of Computer-Aided Design &amp; Computer Graphics, December 2010. </p> </li> </ol>"},{"location":"reviewer/","title":"Reviewer","text":""},{"location":"reviewer/#paperconference","title":"Paper/Conference","text":"<ul> <li>IEEE T-MM</li> <li>ECCV</li> <li>MULTIMEDIA SYST</li> <li>IJMLC</li> <li>CLUSTER COMPUT</li> <li>IET Comput. Vis.</li> <li>ICCMS</li> <li>Applied Intelligence</li> <li>etc.</li> </ul>"}]}